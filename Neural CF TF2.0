import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import tensorflow as tf
from sklearn.metrics import accuracy_score
from tensorflow.keras import optimizers, losses, metrics
from tensorflow import keras


# embedding_class

class SingleEmb(keras.layers.Layer):
    def __init__(self, emb_type, sparse_feature_column):
        super().__init__()
        # 取出sparse columns
        self.sparse_feature_column = sparse_feature_column
        self.embedding_layer = keras.layers.Embedding(sparse_feature_column.vocabulary_size,
                                                      sparse_feature_column.embedding_dim,
                                                      name=emb_type + "_" + sparse_feature_column.name)

    def call(self, inputs):
        return self.embedding_layer(inputs)


class NearalCF(keras.models.Model):
    def __init__(self, sparse_feature_dict, MLP_layers_units):
        super().__init__()
        self.sparse_feature_dict = sparse_feature_dict
        self.MLP_layers_units = MLP_layers_units
        self.GML_emb_user = SingleEmb('GML', sparse_feature_dict['user_id'])
        self.GML_emb_item = SingleEmb('GML', sparse_feature_dict['item_id'])
        self.MLP_emb_user = SingleEmb('MLP', sparse_feature_dict['user_id'])
        self.MLP_emb_item = SingleEmb('MLP', sparse_feature_dict['item_id'])
        self.MLP_layers = []
        for units in MLP_layers_units:
            self.MLP_layers.append(keras.layers.Dense(units, activation='relu'))
        self.NeuMF_layer = keras.layers.Dense(1, activation='sigmoid')

    def call(self, X):
        # 输入X为n行两列的数据，第一列为user，第二列为item
        GML_user = keras.layers.Flatten()(self.GML_emb_user(X[:, 0]))
        GML_item = keras.layers.Flatten()(self.GML_emb_item(X[:, 1]))
        GML_out = tf.multiply(GML_user, GML_item)
        MLP_user = keras.layers.Flatten()(self.MLP_emb_user(X[:, 0]))
        MLP_item = keras.layers.Flatten()(self.MLP_emb_item(X[:, 1]))
        MLP_out = tf.concat([MLP_user, MLP_item], axis=1)
        for layer in self.MLP_layers:
            MLP_out = layer(MLP_out)
        # emb的类型为int64，而dnn之后的类型为float32，否则报错
        GML_out = tf.cast(GML_out, tf.float32)
        MLP_out = tf.cast(MLP_out, tf.float32)
        concat_out = tf.concat([GML_out, MLP_out], axis=1)
        return self.NeuMF_layer(concat_out)


    def train(self, X):
        feature_columns_dict = {'user_id': SparseFeat('user_id', data.userId.nunique(), 8),
                                'item_id': SparseFeat('item_id', data.movieId.nunique(), 8)}

        model = NearalCF(feature_columns_dict, [16, 8, 4])
        model.compile(loss=keras.losses.binary_crossentropy,
                      optimizer=keras.optimizers.Adam(0.001),
                      metrics=['acc'])
        model.fit(X,
                  np.array(train_set[2]),
                  batch_size=BATCH,
                  epochs=5, verbose=2, validation_split=0.1)

        X_test = np.array([test_set[0], test_set[1]]).T
        loss, acc = model.evaluate(X_test, np.array(test_set[2]), batch_size=BATCH, verbose=0)
        print(loss, acc)
